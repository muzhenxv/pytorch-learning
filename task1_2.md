pytorch和tensorflow相比，在和python及numpy的结合上确实非常让人舒服。
动态图设计可以随时查看变量，也非常有利于debug。

task1主要是线性回归，softmax和mlp。为什么使用softmax来进行最后的概率归一化？或许和lr一样是一种最大熵模型的等价？mlp如果不加激活函数，那么仿射函数的堆叠依旧是仿射函数，这点很重要。

task2主要是文本预处理，语言模型和rnn。文本预处理涉及分词，停用词等。语言模型是比较顺畅的一种条件概率思维，同时为了简化计算复杂性，依据马尔可夫假设，进行了n元截断。
